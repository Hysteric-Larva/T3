{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. [Opcional] Cadenas de Markov\n",
    "---\n",
    "> *Dado que esta actividad es opcional, el puntaje obtenido si se realiza será equivalente a un bonus sobre el promedio final de notas de tareas.*\n",
    "\n",
    "En esta sección emplearemos un modelo **no supervisado** especializado en secuencias, como lo son las cadenas de markov, para modelar series de tiempo, es decir una serie de registros (tı́picamente valores reales) regularmente indexados en el tiempo. Parea ello utilizaremos el dataset denominado “*international airline passengers*” [[5]](#refs). La tarea consiste en predecir el número de pasajeros (miles) en vuelos internacionales.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/Fyf0LK6.png\" title=\"Title text\" width=\"80%\" />\n",
    "\n",
    "Los datos pueden ser descargados a través del siguiente __[link](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line)__. También están disponibles en Kaggle a través del siguiente __[link](https://www.kaggle.com/andreazzini/international-airline-passengers)__\n",
    "\n",
    "Para la actividad se trabajará con la librería de *sklearn* para aprendizaje sobre secuencias HMM (*Hidden Markov Model*), también puede acudir a la documentación online a través del siguiente __[link](https://hmmlearn.readthedocs.io/en/latest/tutorial.html#available-models)__.\n",
    "```\n",
    "pip install --upgrade hmmlearn\n",
    "conda install -c omnia hmmlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente es necesario mencionar lo que son los modelos NO supervisados de Machine Learninng en contraste con los que ya fueron estudiados con anterioridad a través de las otras tareas. Este úlltimo depende únicamente de la información observada y generalmente es utilizado para tratar variables que no se posea información certera, como un conjunto de datos aleatorios.\n",
    "\n",
    "A continuación se importarán algunas librerias y se definirá una función que calcule la matriz de estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hmmlearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-89f8c2b8c6f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhmmlearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hmmlearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn.hmm import GMMHMM\n",
    "from  sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_matrix(cm, states,title='Transition Probabilities',cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(states))\n",
    "    plt.xticks(tick_marks, states)\n",
    "    plt.yticks(tick_marks, states)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "    plt.ylabel('Origin state')\n",
    "    plt.xlabel('Destination state')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Escriba una función que cargue los datos, los divida en conjuntos de entrenamiento y de pruebas. En base a como trabajan las cadenas de markov ¿Es necesario escalar los datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinceramente no le veo la utilidad de reescalar los datos, debido al hecho de que como se utilizarán cadenas de Markov, el resultado siguiente dependerá del anterior (vea dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_f = \"international-airline-passengers.csv\"\n",
    "dataframe = pd.read_csv(name_f,sep=';',usecols=[1],engine='python',skipfooter = 3)\n",
    "dataframe[:] = dataframe[:].astype('float32')\n",
    "X_train, X_test = dataframe[:96].values, dataframe[96:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataframe consta de solo una entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos en cuestión rondan entre el intervalo 104-622 y corresponden a valores enteros como muestra la visualizacion siguiente del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien cabe destacar que tanto los conjuntos de entrenamiento como prueba son los mismos y es por la razón que ya se mencionó, que cada estado actual depende del anterior y así el siguiente del actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Para resolver el problema defina un modelo de cadena de markov de primer orden con estados ocultos (*hidden markov model*) simple con un generador de datos observados que se distribuye normal $p(x_t|s_t)=\\mathcal{N}(\\mu_{s},\\sigma_{s})$. Para evaluar mida la log-verosimilitud (*log-likelihood*) del modelo sobre el conjunto de entrenamiento y de pruebas. Comente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo por curiosidad quise ver como influenciaba la cantidad de estados considerados sobre el score del modelo, el cual tiene por nombre log verosimilitud, que mide el valor probabilistico de algun dato con respecto a los demás para determinar los siguientes, es decir, el peso del valor actual para la siguiente transición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "x=[]\n",
    "y =[]\n",
    "y_test=[]\n",
    "for i in range(2,40,1):\n",
    "#n_state = 8\n",
    "    markov_model = hmm.GaussianHMM(n_components=i, n_iter=500)\n",
    "    markov_model.fit(X_train)\n",
    "    x.append(i)\n",
    "    y.append(markov_model.score(X_train))\n",
    "    y_test.append(markov_model.score(X_test))   \n",
    "plt.plot(x,y,label=\"Log-likehood del conjunto de entrenamiento\")\n",
    "plt.plot(x,y_test,label=\"Log-likehood del conjunto de pruebas\")\n",
    "plt.title(\"Log-likehood vs número de estados\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que esta probabilidad cada vez aumenta y es por el hecho de que al considerar más estados, implicitamente se consideran más clases y el problema se transforma (no del todo) en uno de clasificación, pero que se ve limitado al momento de predecir el estado siguiente por overfitting\n",
    "\n",
    "Para concluir se considerarán 5 estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state = 5\n",
    "markov_model = hmm.GaussianHMM(n_components=n_state, n_iter=500)\n",
    "markov_model.fit(X_train)\n",
    "\n",
    "print(\"Log-likehood con 5 estados del conjunto de entrenamiento\",markov_model.score(X_train))\n",
    "print(\"Log-likehood con 5 estados del conjunto de pruebas\",markov_model.score(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se genera un conjunto de probabilidad que se distribuye normalmente.\n",
    "\n",
    "Cabe destacar que log-verosimilitud calcula el logaritmo del error probabilistico del conjunto de entrenamiento considerando 100 iteraciones máximas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Analice cualitativamente lo que aprendió el modelo a través de las distribuciones de probabilidad de las observaciones para un estado oculto dado, esto es, $p(x_t|s_t)$, y las distribuciones de probabilidad de transición $p(s_{t+1}|s_t)$. Comente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_state):\n",
    "    r = norm(markov_model.means_[i], np.sqrt( markov_model.covars_[i,0])).rvs(10000)\n",
    "    sns.distplot(r,kde=True, hist=False,label=\"Estado \"+str(i))\n",
    "plt.legend()\n",
    "plt.title(\"Distribuciones de cada estado\")\n",
    "plt.show()\n",
    "plot_state_matrix(markov_model.transmat_,np.arange(n_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí lo importante es que se clasifican los distintos estados a través de varias distribuciones de probabilidad que se intercectan por el hecho de que en cadena de Markov, la probabilidad de un evento depende de alguno anterior. El segundo diagrama resume el comportamiento de estas transiciones ya mencionadas. En la columna X se distribuyen de manera ordena los intervalos por categorí.\n",
    "El área bajo la curva en cada intervalo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d) Gracias a que el modelo no predice un valor único, sino que una distribución de probabilidad (incerteza en cada valor continuo), realice un gráfico de ésto, es decir, visualice el intervalo de confianza en que el modelo predice en cada instante de tiempo, dado el estado oculto, y contrarréstelo con la secuencia original. Hágalo para el conjunto de entrenamiento y de pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico muestra el comportamiento de los datos a través de los distintos estados que va pasando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_state = markov_model.predict(X_test) #predice el estado, no el valor\n",
    "plt.fill_between(np.arange(X_test.shape[0]),markov_model.means_[X_state][:,0]-1.96*np.sqrt(markov_model.covars_[X_state])[:,0,0], markov_model.means_[X_state][:,0]+1.96*np.sqrt(markov_model.covars_[X_state])[:,0,0])\n",
    "plt.plot(markov_model.means_[X_state][:,0],'g*-',label=\"Prediccion de la media\")\n",
    "plt.plot(X_test,'ro-',label=\"Data\") #-- here put train or val\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e) Dado que se ve que el problema no puede ser modelado de manera adecuada con 3 estados distintos (valores que puede tomar el estado oculto en cada instante de tiempo, $s_t$). Experimente con variar la cantidad de éstos  ¿Qué sucede si aumenta hasta tener la misma cantidad de estados que la cantidad de datos? Visualice lo que estime conveniente, además de medir el *log-likelihood* en cada conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que el enunciado anteriormente no especifico que esto último debiese ser con 3 estados y ya se experimentó, se colocarán 96 estados, de modo que el sistema arroja un error porque siempre van a existir transiciones que pasan a más de un valor distinto, por lo que debiese ser eso la causa del error.\n",
    "\n",
    "Se dejará comentado para evitar problemas en la ejecucion general del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_state= 96\n",
    "#markov_model = hmm.GaussianHMM(n_components=n_state, n_iter=100)\n",
    "#markov_model.fit(X_train)\n",
    "\n",
    "#print(\"Log-likehood con 100 estados del conjunto de entrenamiento\",markov_model.score(X_train))\n",
    "#print(\"Log-likehood con 100 estados del conjunto de pruebas\",markov_model.score(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f) Debido a que el modelo no predice el valor continuo directamente, sino que predice el estado oculto de cada instante de tiempo, es necesario hacer un muestreo para obtener el valor continuo (o si desea, quedarse con la media). Realice este muestreo y evalúe la métrica de MSE (*Mean Square Error*) sobre el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se trabaja con error cuadratico y los valores en cuestión rondan en un intervalo (0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_state = markov_model.predict(X_test) #predice el estado, no el valor\n",
    "X_output = norm( markov_model.means_[X_state], np.sqrt(markov_model.covars_[X_state][:,0]) ).rvs() #rvs is sample\n",
    "print(\"Error Asociado = \",mse(X_test, X_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ¿Cambian mucho los resultados si se emplea una mezcla de gausianas como modelo para $p(x_t|s_t)$ en ves de que cada estado pertenezca a un único modelo Gausiano (distribución normal)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y =[]\n",
    "y_test=[]\n",
    "for i in range(2,40,1):\n",
    "#n_state = 8\n",
    "    markov_model = GMMHMM(n_components=n_state, n_mix=5, n_iter=1000)\n",
    "    markov_model.fit(X_train)\n",
    "    x.append(i)\n",
    "    y.append(markov_model.score(X_train))\n",
    "    y_test.append(markov_model.score(X_test))   \n",
    "plt.plot(x,y,label=\"Log-likehood del conjunto de entrenamiento\")\n",
    "plt.plot(x,y_test,label=\"Log-likehood del conjunto de pruebas\")\n",
    "plt.title(\"Log-likehood vs número de estados\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico se ve un comportamiento casi oscilatorio del log likehood a medida que cambian los números de estados y es porque no existe una dependencia directa entre la cantidad de estados al considerar una única distribución normal, por lo que debiese entorpecerse las predicciones pero no necesariamente el entrenamiento que debiese tener un comportamiento lineal al solo considerar una distribucion.\n",
    "Al aplicar una distribución de mezclas gaussianas, permitimos que la dsitribución de probabilidad no sea determinada únicamente por una gaussiana, sinó que sea por la sobreposicione de varias, de esta forma, las distribuciones pueden no estar tan centradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state_matrix(markov_model.transmat_,np.arange(n_state))#da lo mismo lo anterior si consideramos 1 estado solamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_state = markov_model.predict(X_test) #predice el estado, no el valor\n",
    "#X_output = norm( markov_model, np.sqrt(markov_model.covars[:,0]) ).rvs() #rvs is sample\n",
    "print(\"Error Asociado = \",mse(X_test, X_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se redujo el error, pero debe ser por el hecho de que las variables poseen una distribucion más parecida a una normal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
